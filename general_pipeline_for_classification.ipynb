{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renaops/GeneralNNClassificatorPytorch/blob/main/general_pipeline_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ3mlKjRgcT3"
      },
      "source": [
        "# $Universidade$ $Federal$ $de$ $Viçosa$ $(UFV)$ - Campus Viçosa\n",
        "\n",
        "### Trabalho Final\n",
        "\n",
        "**Alunos:** Erick Lima Figueiredo, Guilherme Oliveira Fonseca e Renan Lopes |\n",
        "**MA:** 98898, 98889 e 97370\n",
        "\n",
        "**Professor:** Lucas Nascimento Ferreira\n",
        "\n",
        "**Disciplina:** Aprendizado em Redes Neurais Profundas (INF 721)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amQm5LaGLTI-"
      },
      "source": [
        "## Dataset: A neural network for classifying image data of natural scenes from around the world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYbyVo1HLYAd"
      },
      "source": [
        "**Source Dataset:** https://www.kaggle.com/datasets/puneet6060/intel-image-classification/data, https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification/data\n",
        "\n",
        "**Dataset Google Drive** https://drive.google.com/drive/folders/1hm0LIi2OD2-CirIbJa3E_4Rg9zyPuJoL?usp=sharing\n",
        "\n",
        "**Code Repo:** https://github.com/renaops/IntelImageClassificationNN\n",
        "\n",
        "**Google Colab:** https://colab.research.google.com/drive/1OSpWIk_VxjrZIXt47-DgpX5XCvpKjVMk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lnjuICXe1U7"
      },
      "source": [
        "### 1. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am0kcNoYe4Rt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import v2 as transforms_v2\n",
        "\n",
        "\n",
        "drive = None\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except Exception as e:\n",
        "    print('Você está fora do google colab!')\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yBNidlDuhhEF",
        "outputId": "eb14e1e4-578d-417d-b1ff-e54eb4f140fd"
      },
      "outputs": [],
      "source": [
        "USING_CUDA = torch.cuda.is_available()\n",
        "torch.manual_seed(1)\n",
        "\n",
        "f'Pytorch {\"\" if USING_CUDA else \"não \"}está usando o CUDA!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsrjSzfte0lV",
        "outputId": "a4e22296-104e-434b-8c08-bc3688fe6aa7"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IS_TRAINING = False\n",
        "\n",
        "DATA_FOLDER_NAME = 'data'\n",
        "MODEL_NAME = 'cat_dog_classification'\n",
        "SAVE_MODEL_PATH = './models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGPJFKnSJvXv"
      },
      "source": [
        "#### 1.1 Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29d0Bwm_IvrK"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(train_losses, val_losses, num_epochs, size=(8, 5)):\n",
        "    \"\"\"\n",
        "    Plot the learning curve based on training and validation losses over epochs.\n",
        "\n",
        "    Args:\n",
        "    - train_losses (list): List of training losses for each epoch.\n",
        "    - val_losses (list): List of validation losses for each epoch.\n",
        "    - num_epochs (int): Total number of training epochs.\n",
        "    - size (tuple, optional): Figure size (width, height). Default is (8, 5).\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "\n",
        "    Example:\n",
        "    >>> train_loss = [0.1, 0.08, 0.05, 0.04]\n",
        "    >>> val_loss = [0.2, 0.15, 0.1, 0.08]\n",
        "    >>> plot_learning_curve(train_loss, val_loss, num_epochs=4)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=size)\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, marker='o', linestyle='-', color='#ff5a7d', label='Training Loss')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, marker='x', linestyle='-', color='#ff9e00', label='Validation Loss')\n",
        "\n",
        "    plt.title('Learning Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Average Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(conf_matrix, class_labels, title):\n",
        "    \"\"\"\n",
        "    Plot a confusion matrix.\n",
        "\n",
        "    Args:\n",
        "    - conf_matrix (array-like): Confusion matrix.\n",
        "    - class_labels (list): List of class labels.\n",
        "    - title (str): Title for the plot.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "\n",
        "    Example:\n",
        "    >>> confusion_matrix = [[20, 5], [2, 30]]\n",
        "    >>> class_labels = ['Class A', 'Class B']\n",
        "    >>> plot_confusion_matrix(confusion_matrix, class_labels, title='Model Performance')\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    \n",
        "    inverted_conf_matrix = np.fliplr(conf_matrix)\n",
        "    \n",
        "    sns.heatmap(inverted_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", yticklabels=class_labels, xticklabels=class_labels[::-1])\n",
        "    \n",
        "    plt.title(f'Confusion Matrix {title}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_class_distribution(dataframe, column_name, title):\n",
        "    \"\"\"\n",
        "    Plot the distribution of classes in a specified column of a DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - dataframe (pandas.DataFrame): The DataFrame containing the data.\n",
        "    - column_name (str): The name of the column representing the classes.\n",
        "    - title (str): The title for the plot.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "\n",
        "    Example:\n",
        "    >>> import pandas as pd\n",
        "    >>> import seaborn as sns\n",
        "    >>> data = {'Class': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C']}\n",
        "    >>> df = pd.DataFrame(data)\n",
        "    >>> plot_class_distribution(df, 'Class', title='Class Distribution')\n",
        "    \"\"\"\n",
        "    sns.countplot(x=column_name, data=dataframe, order=sorted(dataframe[column_name].unique()))\n",
        "    plt.title(f'{title} Distribution')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK0gEJuJfYMw"
      },
      "source": [
        "### 2. Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_noWw7f1ELkz"
      },
      "outputs": [],
      "source": [
        "def get_content_from_partition(partition, data_path):\n",
        "    \"\"\"\n",
        "    Retrieve a list of dictionaries containing information about images in a specified partition.\n",
        "\n",
        "    Args:\n",
        "    - partition (str): The partition name, such as 'train', 'test', or 'validation'.\n",
        "    - data_path (str): The base path where the data is stored.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of dictionaries, where each dictionary represents an image with the following keys:\n",
        "        - 'class': The class or label of the image.\n",
        "        - 'img': The full path to the image file.\n",
        "\n",
        "    Example:\n",
        "    >>> data = get_content_from_partition('train', '/path/to/data')\n",
        "    >>> print(data)\n",
        "    [{'class': 'cat', 'img': '/path/to/data/train/cat/cat_image.jpg'},\n",
        "        {'class': 'dog', 'img': '/path/to/data/train/dog/dog_image.png'},\n",
        "        ...]\n",
        "    \"\"\"\n",
        "    partition_data = []\n",
        "    for clazz in os.listdir(os.path.join(data_path, partition)):\n",
        "        for img in os.listdir(os.path.join(data_path, partition, clazz)):\n",
        "            if img.endswith('.jpg') or img.endswith('.png'):\n",
        "                partition_data.append({'class': clazz, 'img': os.path.join(data_path, partition, clazz, img)})\n",
        "\n",
        "    return partition_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuyK1BiGMqAw",
        "outputId": "a606fc19-086d-4e60-9af4-7b21c3ce31d9"
      },
      "outputs": [],
      "source": [
        "if drive:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    data_path = '/content/drive/Shareddrives/Deep Learning'\n",
        "else:\n",
        "    data_path = './'\n",
        "\n",
        "data_path += DATA_FOLDER_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I90aebBrCVSm"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(get_content_from_partition('train', data_path))\n",
        "val_df = pd.DataFrame(get_content_from_partition('validation', data_path))\n",
        "test_df = pd.DataFrame(get_content_from_partition('test', data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhHmNM8eD9B9",
        "outputId": "2fe3406e-2c21-41b5-a63f-1714b336e75c"
      },
      "outputs": [],
      "source": [
        "print(f'> Train size: {len(train_df)}\\n> Val size: {len(val_df)}\\n> Test size: {len(test_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x6jDWBlvJMHJ",
        "outputId": "d8093759-1a0e-414a-fbe8-ddab30adf006"
      },
      "outputs": [],
      "source": [
        "plot_class_distribution(train_df, 'class', 'Train')\n",
        "plot_class_distribution(val_df, 'class', 'Validation')\n",
        "plot_class_distribution(test_df, 'class', 'Test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwaj8Q-5fuD5"
      },
      "source": [
        "### 3. Preprocessing and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcTvWo0tOse3"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "class GenericDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom PyTorch dataset for working with image data in environments.\n",
        "\n",
        "    Args:\n",
        "    - df (pandas.DataFrame): The DataFrame containing image file paths and class labels.\n",
        "    - transform (callable, optional): A function/transform that takes in an image and returns a transformed version.\n",
        "    - target_name (str, optional): The name of the column in 'df' containing class labels. Default is 'class'.\n",
        "    - shuffle (bool, optional): Whether to shuffle the dataset. Default is True.\n",
        "\n",
        "    Attributes:\n",
        "    - class_names (list): List of unique class names present in the dataset.\n",
        "    - data (pandas.DataFrame): The DataFrame representing the dataset.\n",
        "\n",
        "    Methods:\n",
        "    - __len__: Returns the number of samples in the dataset.\n",
        "    - __getitem__: Returns the image and label for a given index.\n",
        "\n",
        "    Example:\n",
        "    >>> dataset = GenericDataset(df, transform=transforms.ToTensor(), target_name='label', shuffle=True)\n",
        "    >>> print(dataset.class_names)\n",
        "    ['class_A', 'class_B', 'class_C']\n",
        "    >>> print(len(dataset))\n",
        "    1000\n",
        "    >>> img, label = dataset[0]\n",
        "    >>> print(img.shape, label)\n",
        "    (3, 224, 224), 0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, transform=None, target_name='class', shuffle=True):\n",
        "        self._data = self._shuffle(df) if shuffle else df\n",
        "        self._transform = transform\n",
        "        self._class_names = sorted(list(self.data[target_name].unique()))\n",
        "\n",
        "    @property\n",
        "    def class_names(self):\n",
        "        \"\"\"List of unique class names present in the dataset.\"\"\"\n",
        "        return self._class_names\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        \"\"\"The DataFrame representing the dataset.\"\"\"\n",
        "        return self._data\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns the image and label for a given index.\"\"\"\n",
        "        img = read_image(self._data.loc[idx, 'img'])[:3, :, :]\n",
        "\n",
        "        label = self._class_names.index(self._data.loc[idx, 'class'])\n",
        "\n",
        "        if self._transform:\n",
        "            img = self._transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def _shuffle(self, df):\n",
        "        \"\"\"Shuffles the DataFrame.\"\"\"\n",
        "        return df.sample(frac=1).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOJQQEe4TiPl"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "def custom_transforms(new_size=(224,224), is_training=False):\n",
        "    \"\"\"\n",
        "    Returns a composed set of image transformations using torchvision.transforms.\n",
        "\n",
        "    The transformations include:\n",
        "    - Convert the image to dtype torch.float32 with scaling.\n",
        "    - Resize the image to (224, 224) with antialiasing.\n",
        "    - Apply random rotation to the image within the range of -45 to 45 degrees.\n",
        "    - Randomly flip the image horizontally with a probability of 0.5.\n",
        "\n",
        "    Returns:\n",
        "    torchvision.transforms.Compose: Composed set of image transformations.\n",
        "\n",
        "    Example:\n",
        "    >>> transform = my_transforms()\n",
        "    >>> img_transformed = transform(img)\n",
        "    \"\"\"\n",
        "\n",
        "    layers = [transforms_v2.ToDtype(torch.float32, scale=True),\n",
        "              transforms_v2.Resize(size=new_size, antialias=True)]\n",
        "\n",
        "    if is_training:\n",
        "        layers.append(transforms_v2.RandomRotation(degrees=(-45, 45)))\n",
        "        layers.append(transforms_v2.RandomHorizontalFlip(p=0.5))\n",
        "\n",
        "    return transforms_v2.Compose(layers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCATu3F7K00W"
      },
      "outputs": [],
      "source": [
        "train_dataset = GenericDataset(train_df, transform=custom_transforms(is_training=True))\n",
        "val_dataset = GenericDataset(val_df, transform=custom_transforms())\n",
        "test_dataset = GenericDataset(test_df, transform=custom_transforms())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "A-Ww3PZjbWlW",
        "outputId": "5af16238-0cbf-4350-c951-3b53652b87fb"
      },
      "outputs": [],
      "source": [
        "#TODO: MELHORAR ISSO\n",
        "print('This is a ' + train_dataset.class_names[train_dataset[0][1]], end='\\n\\n')\n",
        "transforms.ToPILImage()(train_dataset[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UhZF7wCgCA7"
      },
      "source": [
        "# 4. Model Architecture and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtfmOBprLvya"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 50\n",
        "NUM_CLASSES = len(train_dataset.class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc5tCPVegeYH",
        "outputId": "f2db291a-c8bd-4b3d-ec6f-9c797cc27b4c"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "workers = os.cpu_count()\n",
        "print(f\"Thread workers: {workers}\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey1K-vB0ISf8"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "class GenericClassificationNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network (CNN) for environmental classification.\n",
        "\n",
        "    Args:\n",
        "    - num_classes (int): Number of classes for classification.\n",
        "\n",
        "    Attributes:\n",
        "    - pool (nn.MaxPool2d): Max pooling layer.\n",
        "    - conv1, conv2, conv3, conv4, conv5, conv6 (nn.Conv2d): Convolutional layers.\n",
        "    - batch1, batch2, batch3, batch4, batch5, batch6, batch7 (nn.BatchNorm2d or nn.BatchNorm1d): Batch normalization layers.\n",
        "    - dropout1, dropout2, dropout3, dropout4 (nn.Dropout): Dropout layers.\n",
        "    - fc1 (nn.Linear): Fully connected layer.\n",
        "    - out (nn.Linear): Output layer.\n",
        "\n",
        "    Methods:\n",
        "    - forward: Defines the forward pass of the network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(GenericClassificationNet, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.batch1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "        self.batch2 = nn.BatchNorm2d(32)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
        "        self.batch3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.batch4 = nn.BatchNorm2d(64)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3)\n",
        "        self.batch5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
        "        self.batch6 = nn.BatchNorm2d(128)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 24 * 24, 128)\n",
        "        self.batch7 = nn.BatchNorm1d(128)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.out = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the network.\n",
        "\n",
        "        Args:\n",
        "        - x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor: Output tensor.\n",
        "        \"\"\"\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.batch1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.batch2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.batch3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.batch4(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.batch5(x)\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.batch6(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 24 * 24)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.batch7(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G3P2_LbzR60"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "def calc_val_loss(model, dataloader, loss_function):\n",
        "    \"\"\"\n",
        "    Calculate the average validation loss for a given model, dataloader, and loss function.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The neural network model.\n",
        "    - dataloader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
        "    - loss_function (torch.nn.modules.loss._Loss): The loss function used for evaluation.\n",
        "\n",
        "    Returns:\n",
        "    float: The average validation loss.\n",
        "\n",
        "    Example:\n",
        "    >>> net = GenericClassificationNet(num_classes=10)\n",
        "    >>> val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    >>> criterion = nn.CrossEntropyLoss()\n",
        "    >>> val_loss = calc_val_loss(net, val_dataloader, criterion)\n",
        "    >>> print(val_loss)\n",
        "    0.1234\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0.0\n",
        "        for batch in dataloader:\n",
        "            imgs, labels = batch\n",
        "\n",
        "            if USING_CUDA:\n",
        "                imgs = imgs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            batch_loss = loss_function(outputs, labels).item()\n",
        "            total_loss += batch_loss\n",
        "\n",
        "        average_loss = total_loss / len(dataloader)\n",
        "\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn83p9NXhTat"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    if seconds < 60:\n",
        "        return f'{seconds:.2f}s'\n",
        "    else:\n",
        "        m, s = divmod(seconds, 60)\n",
        "        h, m = divmod(m, 60)\n",
        "\n",
        "        return f'{int(m)}m{s:.2f}s' if h <= 0 else f'{h}h{int(m)}m{s:.2f}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5u4_NVHKeKB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "model = GenericClassificationNet(NUM_CLASSES)\n",
        "\n",
        "if USING_CUDA:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug-Hu4CrqIBB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQPC_raIrRnZ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "def optimize(model, train_loader, val_loader, loss_func, optimizer, num_epochs, output_path):\n",
        "    \"\"\"\n",
        "    Train and optimize a neural network model.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The neural network model.\n",
        "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
        "    - val_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
        "    - loss_func (torch.nn.modules.loss._Loss): The loss function used for training.\n",
        "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
        "    - num_epochs (int): Number of training epochs.\n",
        "    - output_path (str): File path to save the trained model.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Lists of training and validation losses over epochs.\n",
        "\n",
        "    Example:\n",
        "    >>> net = GenericClassificationNet(num_classes=10)\n",
        "    >>> train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    >>> val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    >>> criterion = nn.CrossEntropyLoss()\n",
        "    >>> optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    >>> train_losses, val_losses = optimize(net, train_dataloader, val_dataloader, criterion, optimizer, num_epochs=10, output_path='model.pth')\n",
        "    \"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "        total_time = 0\n",
        "        total_loss = 0.0\n",
        "\n",
        "        print(f'Epoch: {epoch}/{num_epochs}')\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            start_time = time.time()\n",
        "            optimizer.zero_grad()\n",
        "            imgs, labels = batch\n",
        "\n",
        "            if USING_CUDA:\n",
        "                imgs = imgs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "\n",
        "            loss = loss_func(model(imgs), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            iteration_time = (time.time() - start_time)\n",
        "            total_time += iteration_time\n",
        "\n",
        "            completion_percentage = (i + 1) / len(train_loader) * 100\n",
        "            formatted_completion_percentage = math.floor(completion_percentage / 3.333)\n",
        "\n",
        "            print(f'\\r{i+1}/{len(train_loader)} [{\"=\"*(formatted_completion_percentage)}{\".\"*(30 - formatted_completion_percentage)}] - {format_time(iteration_time)}/step - Loss: {loss:.6f}', end='', flush=True)\n",
        "\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        val_losses.append(calc_val_loss(model, val_loader, loss_func))\n",
        "        print(f\" || Train Loss:{train_losses[-1]:.6f} - Val Loss:{val_losses[-1]:.6f}\")\n",
        "\n",
        "    print('\\nComplete! =)')\n",
        "    torch.save(model.state_dict(), output_path)\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR6UZeal4pZv",
        "outputId": "b7c0c896-a743-4a51-a9f6-5a230c47471d"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "if IS_TRAINING:\n",
        "    train_losses, val_losses = optimize(model, train_loader, val_loader, loss_func, optimizer, NUM_EPOCHS, os.path.join(SAVE_MODEL_PATH, MODEL_NAME + '.pth'))\n",
        "    plot_learning_curve(train_losses, val_losses, NUM_EPOCHS)\n",
        "else:\n",
        "    model.load_state_dict(torch.load(os.path.join(SAVE_MODEL_PATH, MODEL_NAME+'.pth')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7IJPTjqgIiI"
      },
      "source": [
        "### 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model_accuracy(model, dataloader, n_classes):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a PyTorch model on a given dataloader, calculating accuracy and plotting the ROC curve.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained PyTorch model to be evaluated.\n",
        "        dataloader (torch.utils.data.DataLoader): DataLoader containing the evaluation dataset.\n",
        "        n_classes (int): The number of classes in the classification task.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the accuracy and confusion matrix of the model.\n",
        "            - accuracy (float): The accuracy of the model on the provided dataset.\n",
        "            - confusion_mat (numpy.ndarray): The confusion matrix showing the classification\n",
        "              performance of the model.\n",
        "\n",
        "    This function evaluates the model on the specified dataloader, capturing predictions and ground truth labels.\n",
        "    It calculates accuracy and, if the task is binary classification (n_classes=2), plots the Receiver Operating\n",
        "    Characteristic (ROC) curve with the corresponding Area Under the Curve (AUC) to assess the model's performance.\n",
        "\n",
        "    Note:\n",
        "    - The model is assumed to output logits, and softmax is applied to obtain class probabilities.\n",
        "    - The function requires the scikit-learn library for calculating accuracy, confusion matrix, and ROC curve.\n",
        "\n",
        "    Example:\n",
        "    >>> train_accuracy, conf_matrix = evaluate_model_accuracy(model, train_loader, n_classes=2)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions, reference, probabilities = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            if USING_CUDA:\n",
        "                imgs = imgs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "\n",
        "            logits = model(imgs).data\n",
        "            y_hat = torch.argmax(logits, 1)\n",
        "            probas = torch.nn.functional.softmax(logits, dim=1)[:, 1]\n",
        "\n",
        "            predictions.extend(y_hat.cpu().numpy())\n",
        "            reference.extend(labels.cpu().numpy())\n",
        "            probabilities.extend(probas.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(reference, predictions)\n",
        "    confusion_mat = confusion_matrix(reference, predictions)\n",
        "\n",
        "    if n_classes == 2:\n",
        "        fpr, tpr, _ = roc_curve(reference, probabilities)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "    return accuracy, confusion_mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qzo5MesRrRnZ",
        "outputId": "0a96f96a-2b6c-4462-e6b1-5c776d37086a"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "validation_accuracy, conf_mtrx_validation = evaluate_model_accuracy(model, val_loader, NUM_CLASSES)\n",
        "test_accuracy, conf_mtrx_test = evaluate_model_accuracy(model, test_loader, NUM_CLASSES)\n",
        "\n",
        "print('Validation accuracy:', validation_accuracy)\n",
        "print('Test accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmX-9jTJpILQ"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(conf_mtrx_validation, val_dataset.class_names, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcjlCJ0A7eCQ"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(conf_mtrx_test, test_dataset.class_names, 'Test')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
